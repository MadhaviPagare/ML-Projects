{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43a08475",
   "metadata": {},
   "source": [
    "## Programming Assg\n",
    "#### Machine Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b2aca17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "965be241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First load the dataset into pandas dataframe\n",
    "training = pd.read_csv('dataset/training.csv',header=None,delimiter=',')\n",
    "validation = pd.read_csv('dataset/validation.csv',header=None,delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c5408ec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-315</td>\n",
       "      <td>75</td>\n",
       "      <td>0.205128</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.146667</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-243</td>\n",
       "      <td>75</td>\n",
       "      <td>0.213333</td>\n",
       "      <td>0.186667</td>\n",
       "      <td>0.293333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.186667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-289</td>\n",
       "      <td>77</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.282051</td>\n",
       "      <td>0.220779</td>\n",
       "      <td>0.220779</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-776</td>\n",
       "      <td>118</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.203390</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-388</td>\n",
       "      <td>77</td>\n",
       "      <td>0.226190</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.207792</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1         2         3         4         5         6         7  8\n",
       "0 -315  75   0.205128  0.230769  0.307692  0.146667  0.280000  0.240000  0\n",
       "1 -243  75   0.213333  0.186667  0.293333  0.400000  0.253333  0.186667  0\n",
       "2 -289  77   0.192308  0.230769  0.282051  0.220779  0.220779  0.272727  0\n",
       "3 -776  118  0.271186  0.203390  0.271186  0.200000  0.200000  0.291667  1\n",
       "4 -388  77   0.226190  0.238095  0.250000  0.272727  0.272727  0.207792  1"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d286b5",
   "metadata": {},
   "source": [
    "## Task : A\n",
    "Print total number of samples in the validation dataset: \"dataset/validation.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9f3220d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "task1=pd.read_csv('dataset/validation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a3a71fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       -315   75  0.20512800000000003  0.230769  0.307692  \\\n",
      "0     -243   75   0.213333             0.186667  0.293333   \n",
      "1     -289   77   0.192308             0.230769  0.282051   \n",
      "2     -776   118  0.271186             0.203390  0.271186   \n",
      "3     -388   77   0.226190             0.238095  0.250000   \n",
      "4     -289   75   0.200000             0.173333  0.306667   \n",
      "...    ...   ..        ...                  ...       ...   \n",
      "59994 -707   120  0.233333             0.216667  0.266667   \n",
      "59995 -404   117  0.247863             0.239316  0.205128   \n",
      "59996 -847   120  0.233333             0.208333  0.275000   \n",
      "59997 -201   75   0.200000             0.226667  0.293333   \n",
      "59998 -770   120  0.237705             0.122951  0.295082   \n",
      "\n",
      "       0.14666700000000002      0.28      0.24  0  \n",
      "0      0.400000             0.253333  0.186667  0  \n",
      "1      0.220779             0.220779  0.272727  0  \n",
      "2      0.200000             0.200000  0.291667  1  \n",
      "3      0.272727             0.272727  0.207792  1  \n",
      "4      0.233766             0.298701  0.220779  0  \n",
      "...         ...                  ...       ... ..  \n",
      "59994  0.233333             0.241667  0.250000  1  \n",
      "59995  0.226891             0.218487  0.252101  0  \n",
      "59996  0.233333             0.208333  0.258333  1  \n",
      "59997  0.207792             0.181818  0.298701  0  \n",
      "59998  0.208333             0.216667  0.266667  1  \n",
      "\n",
      "[59999 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "print(task1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238ab297",
   "metadata": {},
   "source": [
    "## Task : B\n",
    "Print two numbers in the format: [n0, n1], where\n",
    "n0 represents number of class=0 (negative) samples and n1 represents number of class=1 (positive) samples in the validation dataset: \"dataset/validation.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e6dabf09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    40060\n",
      "1    19940\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv('dataset/validation.csv',names=['a','b','c','d','e','f','g','h','class'])\n",
    "number=data['class'].value_counts()\n",
    "print(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c860624a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27e9d539",
   "metadata": {},
   "source": [
    "## Task : C\n",
    "Print standard deviation of the second feature: \"The length of shorter sequence\" of the validation dataset: \"dataset/validation.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aea36c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.278652371558504\n"
     ]
    }
   ],
   "source": [
    "TASK_C=data['b'].std()\n",
    "print(TASK_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0876ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25100733",
   "metadata": {},
   "source": [
    "## Task : D\n",
    "Print median (i.e., 50% percentile) of the seventh feature: \"'U' frequencies of sequence 2\" of the validation dataset: \"dataset/validation.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6f148e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2203389999999999\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "ans4=np.percentile(data['g'],50)\n",
    "print(ans4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184f330d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3ca953f",
   "metadata": {},
   "source": [
    "## Task : E\n",
    "Complete the function \"confusion_matrix\" partially defined that takes two arrays of target variable \"y\": y_actual and y_pred denoting ground truth class labels and predicted class labels for the N samples when N is the length of both the arrays. The function should return a list of 4 metrics: TN, FP, FN, TP (in this order)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fe603a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(y_actual, y_pred):\n",
    "    # the function takes two arrays of target variable \"y\": y_actual and y_pred\n",
    "    #    denoting ground truth class labels and predicted class labels for the N samples\n",
    "    #    when N is the length of both the arrays.\n",
    "    # The function should return a list of 4 metrics: TN, FP, FN, TP (in this order).\n",
    "    assert(len(y_actual)==len(y_pred))\n",
    "    \n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "\n",
    "    #@TODO\n",
    "    for z in range(len(y_pred)): \n",
    "        if y_actual[z]==y_pred[z]==1:\n",
    "           TP += 1\n",
    "        if y_pred[z]==1 and y_actual[z]!=y_pred[z]:\n",
    "           FP += 1\n",
    "        if y_actual[z]==y_pred[z]==0:\n",
    "           TN += 1\n",
    "        if y_pred[z]==0 and y_actual[z]!=y_pred[z]:\n",
    "           FN += 1\n",
    "\n",
    "    return [TN,FP, FN, TP]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "68881de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix([1, 0, 1, 1], [0, 0, 1, 1])) #Expected to print: [1, 0, 1, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c4a133",
   "metadata": {},
   "source": [
    "## Task : F\n",
    "You need to complete the accuracy function partially defined in the file that takes a confusion matrix, i.e. the list of the four metrics: [TN, FP, FN, TP], in this order, and return accuracy. In case of Division by Zero error, return -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1524c6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(conf_mat):\n",
    "    # Given a confusion matrix, i.e. the list of four metrics: [TN,FP, FN, TP], in this order\n",
    "    # return accuracy\n",
    "    [TN, FP, FN, TP] = conf_mat\n",
    "    acc_value = 0\n",
    "    try:\n",
    "        acc_value=(TP+TN)/(TP+FP+TN+FN)\n",
    "    except:\n",
    "        acc=-1\n",
    "    return acc_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "610b9b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n"
     ]
    }
   ],
   "source": [
    "conf_mat = confusion_matrix([1, 0, 1, 1], [0, 0, 1, 1])  #Expected to print 0.75\n",
    "print(accuracy(conf_mat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2aa78b6",
   "metadata": {},
   "source": [
    "## Task : G\n",
    "You need to complete the precision function partially defined in the file that takes a confusion matrix, i.e. the list of the four metrics: [TN, FP, FN, TP], in this order, and return precision. It is also known as Positive Predictive Value (PPV). In case of Division by Zero error, return -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c6eb55f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(conf_mat):\n",
    "    # Given a confusion matrix, i.e. the list of four metrics: [TN,FP, FN, TP], in this order\n",
    "    # return precision. It is also known as Positive Predictive Value (PPV)\n",
    "    [TN, FP, FN, TP] = conf_mat\n",
    "    prec_value = 0\n",
    "    try:\n",
    "        prec_value  =TP/(TP+FP)\n",
    "    except:\n",
    "        prec=-1\n",
    "    return prec_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "34c02590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "conf_mat = confusion_matrix([1, 0, 1, 1], [0, 0, 1, 1])  #Expected to print 1.0\n",
    "print(precision(conf_mat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90ba6fe",
   "metadata": {},
   "source": [
    "## Task : H\n",
    "You need to complete the recall function partially defined in the file that takes a confusion matrix, i.e. the list of the four metrics: [TN, FP, FN, TP], in this order, and return recall. It is also known as Sensitivity, or True Positive Rate (TPR). In case of Division by Zero error, return -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "501cd309",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(conf_mat):\n",
    "    # Given a confusion matrix, i.e. the list of four metrics: [TN,FP, FN, TP], in this order\n",
    "    # return recall. It is also known as Sensitivity, or True Positive Rate (TPR)\n",
    "    [TN, FP, FN, TP] = conf_mat\n",
    "    rec_value = 0\n",
    "    try:\n",
    "        rec_value=TP/(TP+FN)\n",
    "    except:\n",
    "        rec=-1\n",
    "    return rec_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b29ef9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "conf_mat = confusion_matrix([1, 0, 1, 1], [0, 0, 1, 1])  #Expected to print 0.6666666666\n",
    "print(recall(conf_mat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f6c9a3",
   "metadata": {},
   "source": [
    "## Task : I\n",
    "You need to complete the F1 function partially defined in the file that takes a confusion matrix, i.e. the list of the four metrics: [TN, FP, FN, TP], in this order, and return F1. It is the harmonic mean of precision and recall. In case of Division by Zero error, return -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cab4cd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def F1(conf_mat):\n",
    "    # Given a confusion matrix, i.e. the list of four metrics: [TN,FP, FN, TP], in this order\n",
    "    # return F1 score. It is the harmonic mean of precision and recall\n",
    "    [TN, FP, FN, TP] = conf_mat\n",
    "    f1_value = 0\n",
    "    \n",
    "    try:\n",
    "        f1_value=2*TP/(2*TP+FN+FP)\n",
    "    except:\n",
    "        f1_value=-1\n",
    "    return f1_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fcc93aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8\n"
     ]
    }
   ],
   "source": [
    "conf_mat = confusion_matrix([1, 0, 1, 1], [0, 0, 1, 1]) #Expected to print 0.8\n",
    "print(F1(conf_mat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2128d772",
   "metadata": {},
   "source": [
    "## Task : J\n",
    "You need to complete the MCC function defined in the file that takes a confusion matrix, i.e. the list of the four metrics: [TN, FP, FN, TP], in this order, and return Matthews Correlation Coefficient (MCC). In case of Division by Zero error, return -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "01ca3913",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def MCC(conf_mat):\n",
    "    # Given a confusion matrix, i.e. the list of four metrics: [TN,FP, FN, TP], in this order\n",
    "    # return Matthews correlation coefficient (MCC)\n",
    "    [TN, FP, FN, TP] = conf_mat\n",
    "    mcc_value = 0\n",
    "    \n",
    "    #@TODO\n",
    "    try:\n",
    "        mcc_value=(TP*TN-FP*FN)/(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))**(1/2))\n",
    "    except:\n",
    "        mcc_value=-1\n",
    "    return mcc_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6b8284c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5773502691896258\n"
     ]
    }
   ],
   "source": [
    "conf_mat = confusion_matrix([1, 0, 1, 1], [0, 0, 1, 1]) #Expected to print 0.5773502691896258\n",
    "print(MCC(conf_mat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be81ef54",
   "metadata": {},
   "source": [
    "## Task : K\n",
    "You need to complete the FDR function defined in the file that takes a confusion matrix, i.e. the list of the four metrics: [TN, FP, FN, TP], in this order, and return False Discovery Rate (FDR). In case of Division by Zero error, return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "15bf9850",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FDR(conf_mat):\n",
    "    # Given a confusion matrix, i.e. the list of four metrics: [TN,FP, FN, TP], in this order\n",
    "    # return False Discovery Rate (FDR)\n",
    "    [TN, FP, FN, TP] = conf_mat\n",
    "    fdr_value = 0\n",
    "    try:\n",
    "        fdr_value = FP / (FP + TP)\n",
    "    except:\n",
    "        fdr_value=-1\n",
    "    return fdr_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dffbe6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "conf_mat = confusion_matrix([1, 0, 1, 1], [0, 0, 1, 1]) #Expected to print 0.0\n",
    "print(FDR(conf_mat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9614d2f8",
   "metadata": {},
   "source": [
    "## Task : L\n",
    "Print as a dataframe containing:\n",
    " {model_name,acc,prec,rec,f1,mcc,FDR} for each of the N models (listed in models/*) after predicting the target variables of the validation data: \"dataset/validation.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "85e17a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/6 [00:00<?, ?it/s]C:\\Users\\MADHAVI\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.24.2 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      " 17%|██████████████                                                                      | 1/6 [00:00<00:04,  1.06it/s]C:\\Users\\MADHAVI\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator KNeighborsClassifier from version 0.24.2 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      " 33%|████████████████████████████                                                        | 2/6 [00:04<00:10,  2.51s/it]C:\\Users\\MADHAVI\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator SVC from version 0.24.2 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      " 50%|██████████████████████████████████████████                                          | 3/6 [02:14<03:01, 60.59s/it]C:\\Users\\MADHAVI\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.24.2 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "C:\\Users\\MADHAVI\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator MLPClassifier from version 0.24.2 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      " 67%|████████████████████████████████████████████████████████                            | 4/6 [02:16<01:14, 37.46s/it]C:\\Users\\MADHAVI\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.24.2 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      " 83%|██████████████████████████████████████████████████████████████████████              | 5/6 [02:17<00:24, 24.22s/it]C:\\Users\\MADHAVI\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator SVC from version 0.24.2 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [02:49<00:00, 28.18s/it]\n"
     ]
    }
   ],
   "source": [
    "#Print as a dataframe containing:\n",
    "# {model_name,acc,prec,rec,f1,mcc,FDR} for each of the N models (listed in model_files) predicting the target variables\n",
    "#  of the validation data.\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "result = pd.DataFrame(columns=['model_name','Accuracy','Precision','Recall','F1','MCC','FDR'])\n",
    "\n",
    "model_files=[\"models/Model_1.pkl\",\"models/Model_2.pkl\",\"models/Model_3.pkl\",\\\n",
    "                            \"models/Model_4.pkl\",\"models/Model_5.pkl\",\"models/Model_6.pkl\"]\n",
    "\n",
    "\n",
    "for file_name in tqdm(model_files):\n",
    "    in_file = open(file_name,'rb')\n",
    "    model = pickle.load(in_file)\n",
    "    in_file.close()\n",
    "\n",
    "    #Do the prediction by calling the \"predict\" member function of the model object on the\n",
    "    # validation data with the 8 features\n",
    "    X_test = validation.iloc[:,:-1]\n",
    "    y_test = validation.iloc[:,-1]\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    \n",
    "    #@TODO: Complete and revise the following...\n",
    "    conf_mat = []\n",
    "    acc = 0\n",
    "    prec = 0\n",
    "    rec = 0\n",
    "    f1 = 0\n",
    "    mcc = 0\n",
    "    fdr = 0\n",
    "    \n",
    "    conf_mat = confusion_matrix(y_test,y_pred)\n",
    "    acc = accuracy(conf_mat)\n",
    "    prec = precision(conf_mat)\n",
    "    rec = recall(conf_mat)\n",
    "    f1 = F1(conf_mat)\n",
    "    mcc = MCC(conf_mat)\n",
    "    fdr = FDR(conf_mat)\n",
    "    \n",
    "    result = result.append(pd.Series([file_name,acc,prec,rec,f1,mcc,fdr],index=result.columns),ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "eab79ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           model_name  Accuracy  Precision   Recall        F1       MCC  \\\n",
      "0  models/Model_1.pkl  0.337583  0.334082   0.99995  0.500835  0.050929   \n",
      "1  models/Model_2.pkl  0.334083  0.332910   0.99995  0.499518  0.028982   \n",
      "2  models/Model_3.pkl  0.667667  0.000000   0.00000  0.000000 -1.000000   \n",
      "3  models/Model_4.pkl  0.390483  0.352497   0.99659  0.520789  0.168805   \n",
      "4  models/Model_5.pkl  0.333583  0.332744   0.99995  0.499330  0.024302   \n",
      "5  models/Model_6.pkl  0.337500  0.334054   0.99995  0.500804  0.050516   \n",
      "\n",
      "        FDR  \n",
      "0  0.665918  \n",
      "1  0.667090  \n",
      "2 -1.000000  \n",
      "3  0.647503  \n",
      "4  0.667256  \n",
      "5  0.665946  \n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1388167d",
   "metadata": {},
   "source": [
    "## Task : M\n",
    "Print the model name with path which is performing superior among the 6 pretrained models in terms of accuracy, given the performance result dataframe from “L”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1552ca2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           model_name  Accuracy  Precision  Recall   F1  MCC  FDR\n",
      "2  models/Model_3.pkl  0.667667  0.0        0.0     0.0 -1.0 -1.0\n"
     ]
    }
   ],
   "source": [
    "maxvalue=result['Accuracy'].max()\n",
    "print(result[result.Accuracy==maxvalue])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa229f32",
   "metadata": {},
   "source": [
    "## Task : N\n",
    "Print the model name with path which is performing the worst among the 6 pretrained models in terms of recall, given the performance result dataframe from “L”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e940ab1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           model_name  Accuracy  Precision  Recall   F1  MCC  FDR\n",
      "2  models/Model_3.pkl  0.667667  0.0        0.0     0.0 -1.0 -1.0\n"
     ]
    }
   ],
   "source": [
    "minvalue=result['Recall'].min()\n",
    "print(result[result.Recall==minvalue])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a6aac4",
   "metadata": {},
   "source": [
    "## Task : O\n",
    "Scale all the features of the validation set using the formula, z = (x-m)/s,\n",
    "    \n",
    "    where m = mean of a feature in the training set: \"dataset/training.csv\"\n",
    "    \n",
    "    s = standard deviation of the feature in the training set: \"dataset/training.csv\"\n",
    "    \n",
    "    #  DO NOT SCALE the target feature.\n",
    "    \n",
    "    # At the end, return a tuple (X, y), with X being a numpy array of shape (N,8) and y is an N dim array and \n",
    "\n",
    "N is the total number of samples in the validation set: \"dataset/validation.csv\".\n",
    "\n",
    "Store the scaled dataset in a variable (preferably a dataframe) named “X_validation_scaled”.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0aa491fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[ 0.77533409, -1.00300496, -0.32595619, ..., -1.67633419,\n",
      "         1.38746318, -0.65836966],\n",
      "       [ 1.1551591 , -1.00300496, -0.1639121 , ...,  3.90687113,\n",
      "         0.75820989, -2.0599923 ],\n",
      "       [ 0.91249312, -0.91031857, -0.57914391, ..., -0.04298002,\n",
      "        -0.00995718,  0.20171516],\n",
      "       ...,\n",
      "       [-2.03115065,  1.08243875,  0.23107655, ...,  0.23369756,\n",
      "        -0.30364175, -0.17656763],\n",
      "       [ 1.37672368, -1.00300496, -0.42723128, ..., -0.32920048,\n",
      "        -0.92930833,  0.88432717],\n",
      "       [-1.62494891,  1.08243875,  0.31742106, ..., -0.31727738,\n",
      "        -0.10698682,  0.04245479]]), array([0, 0, 0, ..., 1, 0, 1], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "val1=validation.iloc[:,:8]\n",
    "for i in val1.axes[1]:\n",
    "    m=np.mean(training.iloc[:,i])\n",
    "    s=np.std(training.iloc[:,i])\n",
    "    val1.iloc[:,i]=(validation.iloc[:,i]-m)/s\n",
    "X_validation_scaled=(np.array(val1),np.array(validation.iloc[:,8]))\n",
    "print(X_validation_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0d7b7c",
   "metadata": {},
   "source": [
    "## Task : P\n",
    "Print as a dataframe containing:\n",
    "  {model_name,acc,prec,rec,f1,mcc,FDR} for each of the N models (listed in model_files) after  predicting the target variables \"y\" (given) for \"X\" (the scaled validation dataset).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9f08e70f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/6 [00:00<?, ?it/s]C:\\Users\\MADHAVI\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.24.2 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      " 17%|██████████████                                                                      | 1/6 [00:00<00:04,  1.20it/s]C:\\Users\\MADHAVI\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator KNeighborsClassifier from version 0.24.2 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      " 33%|████████████████████████████                                                        | 2/6 [00:07<00:17,  4.38s/it]C:\\Users\\MADHAVI\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator SVC from version 0.24.2 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      " 50%|██████████████████████████████████████████                                          | 3/6 [01:36<02:08, 42.93s/it]C:\\Users\\MADHAVI\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.24.2 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "C:\\Users\\MADHAVI\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator MLPClassifier from version 0.24.2 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      " 67%|████████████████████████████████████████████████████████                            | 4/6 [01:38<00:53, 26.75s/it]C:\\Users\\MADHAVI\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.24.2 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      " 83%|██████████████████████████████████████████████████████████████████████              | 5/6 [01:40<00:17, 17.81s/it]C:\\Users\\MADHAVI\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator SVC from version 0.24.2 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [02:09<00:00, 21.52s/it]\n"
     ]
    }
   ],
   "source": [
    "#Print as a dataframe containing:\n",
    "# {model_name,acc,prec,rec,f1,mcc,FDR} for each of the N models (listed in model_files) predicting the target variables\n",
    "#  of the validation data.\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "result1 = pd.DataFrame(columns=['model_name','Accuracy','Precision','Recall','F1','MCC','FDR'])\n",
    "\n",
    "model_files=[\"models/Model_1.pkl\",\"models/Model_2.pkl\",\"models/Model_3.pkl\",\\\n",
    "                            \"models/Model_4.pkl\",\"models/Model_5.pkl\",\"models/Model_6.pkl\"]\n",
    "\n",
    "\n",
    "for file_name in tqdm(model_files):\n",
    "    in_file = open(file_name,'rb')\n",
    "    model = pickle.load(in_file)\n",
    "    in_file.close()\n",
    "\n",
    "    #Do the prediction by calling the \"predict\" member function of the model object on the\n",
    "    # validation data with the 8 features\n",
    "    X_test = val1.iloc[:,:8]\n",
    "    y_test = validation.iloc[:,-1]\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    \n",
    "    #@TODO: Complete and revise the following...\n",
    "    conf_mat = []\n",
    "    acc = 0\n",
    "    prec = 0\n",
    "    rec = 0\n",
    "    f1 = 0\n",
    "    mcc = 0\n",
    "    fdr = 0\n",
    "    \n",
    "    conf_mat = confusion_matrix(y_test,y_pred)\n",
    "    acc = accuracy(conf_mat)\n",
    "    prec = precision(conf_mat)\n",
    "    rec = recall(conf_mat)\n",
    "    f1 = F1(conf_mat)\n",
    "    mcc = MCC(conf_mat)\n",
    "    fdr = FDR(conf_mat)\n",
    "    \n",
    "    result1 = result1.append(pd.Series([file_name,acc,prec,rec,f1,mcc,fdr],index=result1.columns),ignore_index=True)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4040548b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           model_name  Accuracy  Precision    Recall        F1       MCC  \\\n",
      "0  models/Model_1.pkl  0.951233  0.944276   0.906770  0.925143  0.889404   \n",
      "1  models/Model_2.pkl  0.947683  0.936594   0.903761  0.919885  0.881372   \n",
      "2  models/Model_3.pkl  0.965283  0.946492   0.949198  0.947843  0.921828   \n",
      "3  models/Model_4.pkl  0.966100  0.948907   0.949097  0.949002  0.923614   \n",
      "4  models/Model_5.pkl  0.914133  0.887770   0.848947  0.867925  0.804802   \n",
      "5  models/Model_6.pkl  0.953883  0.936816   0.923521  0.930121  0.895760   \n",
      "\n",
      "        FDR  \n",
      "0  0.055724  \n",
      "1  0.063406  \n",
      "2  0.053508  \n",
      "3  0.051093  \n",
      "4  0.112230  \n",
      "5  0.063184  \n"
     ]
    }
   ],
   "source": [
    "print(result1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac093d5",
   "metadata": {},
   "source": [
    "## Task : Q\n",
    "Print the model name with path which is performing superior in terms of accuracy, given the performance result dataframe from “P”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "be1a6362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           model_name  Accuracy  Precision    Recall        F1       MCC  \\\n",
      "3  models/Model_4.pkl  0.9661    0.948907   0.949097  0.949002  0.923614   \n",
      "\n",
      "        FDR  \n",
      "3  0.051093  \n"
     ]
    }
   ],
   "source": [
    "maxvalue=result1['Accuracy'].max()\n",
    "print(result1[result1.Accuracy==maxvalue])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5249c432",
   "metadata": {},
   "source": [
    "## Task : R\n",
    "Print the model name with path which is performing the worst in terms of recall, given the performance result dataframe from “P”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "95773261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           model_name  Accuracy  Precision    Recall        F1       MCC  \\\n",
      "4  models/Model_5.pkl  0.914133  0.88777    0.848947  0.867925  0.804802   \n",
      "\n",
      "       FDR  \n",
      "4  0.11223  \n"
     ]
    }
   ],
   "source": [
    "minvalue=result1['Recall'].min()\n",
    "print(result1[result1.Recall==minvalue])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6efd5f",
   "metadata": {},
   "source": [
    "## Task : S\n",
    "Flip the prediction of Model 1, and then compute and\n",
    " print as a dataframe containing: {acc,prec,rec,f1,mcc,FDR} \n",
    "on the original (i.e., not-scaled) validation dataset: \"dataset/validation.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3c776b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/1 [00:00<?, ?it/s]C:\\Users\\MADHAVI\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.24.2 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.19it/s]\n"
     ]
    }
   ],
   "source": [
    "#Print as a dataframe containing:\n",
    "# {model_name,acc,prec,rec,f1,mcc,FDR} for each of the N models (listed in model_files) predicting the target variables\n",
    "#  of the validation data.\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "result2 = pd.DataFrame(columns=['model_name','Accuracy','Precision','Recall','F1','MCC','FDR'])\n",
    "\n",
    "model_files=[\"models/Model_1.pkl\"]\n",
    "\n",
    "\n",
    "for file_name in tqdm(model_files):\n",
    "    in_file = open(file_name,'rb')\n",
    "    model = pickle.load(in_file)\n",
    "    in_file.close()\n",
    "\n",
    "    #Do the prediction by calling the \"predict\" member function of the model object on the\n",
    "    # validation data with the 8 features\n",
    "    X_test = validation.iloc[:,:-1]\n",
    "    y_test = validation.iloc[:,-1]\n",
    "    y_pred = model.predict(X_test)\n",
    "   \n",
    "   \n",
    "    #@TODO: Complete and revise the following...\n",
    "    conf_mat = []\n",
    "    acc = 0\n",
    "    prec = 0\n",
    "    rec = 0\n",
    "    f1 = 0\n",
    "    mcc = 0\n",
    "    fdr = 0\n",
    "   \n",
    "    conf_mat = confusion_matrix(y_test,np.flip(y_pred))\n",
    "    acc = accuracy(conf_mat)\n",
    "    prec = precision(conf_mat)\n",
    "    rec = recall(conf_mat)\n",
    "    f1 = F1(conf_mat)\n",
    "    mcc = MCC(conf_mat)\n",
    "    fdr = FDR(conf_mat)\n",
    "   \n",
    "    result2 = result2.append(pd.Series([file_name,acc,prec,rec,f1,mcc,fdr],index=result2.columns),ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "129b5a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           model_name  Accuracy  Precision    Recall        F1       MCC  \\\n",
      "0  models/Model_1.pkl  0.333917  0.332239   0.994433  0.498072 -0.002758   \n",
      "\n",
      "        FDR  \n",
      "0  0.667761  \n"
     ]
    }
   ],
   "source": [
    "print(result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7901669d",
   "metadata": {},
   "source": [
    "## Task : T\n",
    "Say, in a confusion matrix, the values of the four metrics are: TP=90, TN=1, FP=4, FN=5. Compute F1_original and MCC_original denoting the F1 and MCC scores.\n",
    "\n",
    "Now, flip the predictions, i.e., positives are now will be predicted as negative, and negatives are going to be predicted as positive. \n",
    "\n",
    "Then, compute F1_flipped and MCC_flipped, denoting corresponding F1 and MCC scores. \n",
    "\n",
    "Print/Return the new {TP, TN, FP, FN, F1_original,MCC_original,F1_flipped, MCC_flipped, COMMENT_string} as a dataframe, where COMMENT_string is a string that will be no longer than 200 characters but is going to be your comment about the F1 and MCC values for the two cases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bcd5c9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  TP TN FP  FN  F1_original  MCC_original  F1_flipped  MCC_flipped  \\\n",
      "0  5  4  1  90  0.952381     0.135242      0.09901    -0.135242      \n",
      "\n",
      "                                                                                                                                    COMMENT_string  \n",
      "0  f1 score higher in F1_original which is good as compared to F1_flipped and Mcc_original is also close to +1 indicating that its a perfect model  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-84-bdc83abc63f6>:2: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  pd.set_option('display.max_colwidth', -1)  # or 199\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', -1)  # or 199\n",
    "result5 = pd.DataFrame(columns=['TP','TN','FP','FN','F1_original','MCC_original','F1_flipped','MCC_flipped','COMMENT_string'])\n",
    "TP=90 \n",
    "TN=1\n",
    "FP=4\n",
    "FN=5\n",
    "F1_original=2*TP/(2*TP+FN+FP)\n",
    "MCC_original=(TP*TN-FP*FN)/(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))**(1/2))\n",
    "FN=90\n",
    "FP=1\n",
    "TN=4\n",
    "TP=5\n",
    "F1_flipped=2*TP/(2*TP+FN+FP)\n",
    "MCC_flipped=(TP*TN-FP*FN)/(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))**(1/2))\n",
    "\n",
    "COMMENT_string=\"f1 score higher in F1_original which is good as compared to F1_flipped and Mcc_original is also close to +1 indicating that its a perfect model\"\n",
    "result5 = result5.append(pd.Series([TP,TN,FP,FN,F1_original,MCC_original,F1_flipped, MCC_flipped, COMMENT_string],index=result5.columns),ignore_index=True)\n",
    "print(result5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93157967",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d084c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76ba9996",
   "metadata": {},
   "source": [
    "## For Graduate Students only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a72e6c",
   "metadata": {},
   "source": [
    "## Task: U\n",
    "This task is a follow up of Task P. There is always cost associated with misclassifications. For instance, if a model predicts a ncRNA (class=1) to be non ncRNA (class=0), further verfication will then follow that includes going through the next generation sequencing of those samples costing USD 20 per sample. On the other hand, cost of predicting a non ncRNA to be ncRNA insignificant as most researchers do not care for ncRNAs. They might put it in a piece of paper as a note costing USD 1 per 5 samples. The same cost applies to correct predictions too.\n",
    "\n",
    "What is the cost of predictions with each of the six models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b4027ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/6 [00:00<?, ?it/s]C:\\Users\\MADHAVI\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.24.2 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      " 17%|██████████████                                                                      | 1/6 [00:00<00:04,  1.19it/s]C:\\Users\\MADHAVI\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator KNeighborsClassifier from version 0.24.2 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      " 33%|████████████████████████████                                                        | 2/6 [00:06<00:15,  3.93s/it]C:\\Users\\MADHAVI\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator SVC from version 0.24.2 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      " 50%|██████████████████████████████████████████                                          | 3/6 [01:33<02:05, 41.76s/it]C:\\Users\\MADHAVI\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.24.2 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "C:\\Users\\MADHAVI\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator MLPClassifier from version 0.24.2 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      " 67%|████████████████████████████████████████████████████████                            | 4/6 [01:35<00:51, 25.95s/it]C:\\Users\\MADHAVI\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.24.2 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      " 83%|██████████████████████████████████████████████████████████████████████              | 5/6 [01:36<00:16, 16.96s/it]C:\\Users\\MADHAVI\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator SVC from version 0.24.2 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [02:07<00:00, 21.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           model_name     Cost\n",
      "0  models/Model_1.pkl  48808.2\n",
      "1  models/Model_2.pkl  49996.2\n",
      "2  models/Model_3.pkl  32057.4\n",
      "3  models/Model_4.pkl  32097.0\n",
      "4  models/Model_5.pkl  71637.6\n",
      "5  models/Model_6.pkl  42195.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Print as a dataframe containing:\n",
    "# {model_name,acc,prec,rec,f1,mcc,FDR} for each of the N models (listed in model_files) predicting the target variables\n",
    "#  of the validation data.\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "result6 = pd.DataFrame(columns=['model_name','Cost'])\n",
    "\n",
    "model_files=[\"models/Model_1.pkl\",\"models/Model_2.pkl\",\"models/Model_3.pkl\",\\\n",
    "                            \"models/Model_4.pkl\",\"models/Model_5.pkl\",\"models/Model_6.pkl\"]\n",
    "\n",
    "\n",
    "for file_name in tqdm(model_files):\n",
    "    in_file = open(file_name,'rb')\n",
    "    model = pickle.load(in_file)\n",
    "    in_file.close()\n",
    "\n",
    "    #Do the prediction by calling the \"predict\" member function of the model object on the\n",
    "    # validation data with the 8 features\n",
    "    X_test = val1.iloc[:,:8]\n",
    "    y_test = validation.iloc[:,-1]\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    \n",
    "    #@TODO: Complete and revise the following...\n",
    "    conf_mat = []\n",
    "    acc = 0\n",
    "    prec = 0\n",
    "    rec = 0\n",
    "    f1 = 0\n",
    "    mcc = 0\n",
    "    fdr = 0\n",
    "    \n",
    "    conf_mat = confusion_matrix(y_test,y_pred)\n",
    "    [TN,FP,FN,TP]=conf_mat\n",
    "    cost=20*FN+0.2*FP+0.2*TN+0.2*TP\n",
    "    \n",
    "    result6 = result6.append(pd.Series([file_name,cost],index=result6.columns),ignore_index=True)\n",
    "\n",
    "print(result6)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a14fbd",
   "metadata": {},
   "source": [
    "## Task: V\n",
    "Please comment on which of the six models is the best on the cost basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "64aa50cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in callback BaseSelectorEventLoop._read_from_self()\n",
      "handle: <Handle BaseSelectorEventLoop._read_from_self()>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\MADHAVI\\anaconda3\\lib\\asyncio\\events.py\", line 81, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\MADHAVI\\anaconda3\\lib\\asyncio\\selector_events.py\", line 120, in _read_from_self\n",
      "    data = self._ssock.recv(4096)\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "Exception in callback BaseSelectorEventLoop._read_from_self()\n",
      "handle: <Handle BaseSelectorEventLoop._read_from_self()>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\MADHAVI\\anaconda3\\lib\\asyncio\\events.py\", line 81, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\MADHAVI\\anaconda3\\lib\\asyncio\\selector_events.py\", line 120, in _read_from_self\n",
      "    data = self._ssock.recv(4096)\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Out of the six models,I think Model3 has low cost so its better one.Low cost results into a good performance.The average loss across a collection of Noncoding Rna and coding Rna samples in a dataset is the cost function which is low in our case.It returns the error output which is less amongst the outcomes that are predicted when its been compared to the actual outcomes.20% are false negative,whereas 0.2% are false positive,0.2% are true negative and 0.2% are true positive so in model3,as the cost value is minimal so model3 behaviour or predictions are almost correctly modelled.so the Model3 is not an undertrained or an overtrained model but a thorougly predicted model'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in callback BaseSelectorEventLoop._read_from_self()\n",
      "handle: <Handle BaseSelectorEventLoop._read_from_self()>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\MADHAVI\\anaconda3\\lib\\asyncio\\events.py\", line 81, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\MADHAVI\\anaconda3\\lib\\asyncio\\selector_events.py\", line 120, in _read_from_self\n",
      "    data = self._ssock.recv(4096)\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "Exception in callback BaseSelectorEventLoop._read_from_self()\n",
      "handle: <Handle BaseSelectorEventLoop._read_from_self()>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\MADHAVI\\anaconda3\\lib\\asyncio\\events.py\", line 81, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\MADHAVI\\anaconda3\\lib\\asyncio\\selector_events.py\", line 120, in _read_from_self\n",
      "    data = self._ssock.recv(4096)\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "Exception in callback BaseSelectorEventLoop._read_from_self()\n",
      "handle: <Handle BaseSelectorEventLoop._read_from_self()>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\MADHAVI\\anaconda3\\lib\\asyncio\\events.py\", line 81, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\MADHAVI\\anaconda3\\lib\\asyncio\\selector_events.py\", line 120, in _read_from_self\n",
      "    data = self._ssock.recv(4096)\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "Exception in callback BaseSelectorEventLoop._read_from_self()\n",
      "handle: <Handle BaseSelectorEventLoop._read_from_self()>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\MADHAVI\\anaconda3\\lib\\asyncio\\events.py\", line 81, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\MADHAVI\\anaconda3\\lib\\asyncio\\selector_events.py\", line 120, in _read_from_self\n",
      "    data = self._ssock.recv(4096)\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "Exception in callback BaseSelectorEventLoop._read_from_self()\n",
      "handle: <Handle BaseSelectorEventLoop._read_from_self()>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\MADHAVI\\anaconda3\\lib\\asyncio\\events.py\", line 81, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\MADHAVI\\anaconda3\\lib\\asyncio\\selector_events.py\", line 120, in _read_from_self\n",
      "    data = self._ssock.recv(4096)\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "Exception in callback BaseSelectorEventLoop._read_from_self()\n",
      "handle: <Handle BaseSelectorEventLoop._read_from_self()>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\MADHAVI\\anaconda3\\lib\\asyncio\\events.py\", line 81, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\MADHAVI\\anaconda3\\lib\\asyncio\\selector_events.py\", line 120, in _read_from_self\n",
      "    data = self._ssock.recv(4096)\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n"
     ]
    }
   ],
   "source": [
    "\"Out of the six models,I think Model3 has low cost so its better one.Low cost results into a good performance.The average loss across a collection of Noncoding Rna and coding Rna samples in a dataset is the cost function which is low in our case.It returns the error output which is less amongst the outcomes that are predicted when its been compared to the actual outcomes.20% are false negative,whereas 0.2% are false positive,0.2% are true negative and 0.2% are true positive so in model3,as the cost value is minimal so model3 behaviour or predictions are almost correctly modelled.so the Model3 is not an undertrained or an overtrained model but a thorougly predicted model\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf512d2",
   "metadata": {},
   "source": [
    "## Task: W\n",
    "Please comment on which of the six models is the best overall. Explain your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "15409d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in callback BaseSelectorEventLoop._read_from_self()\n",
      "handle: <Handle BaseSelectorEventLoop._read_from_self()>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\MADHAVI\\anaconda3\\lib\\asyncio\\events.py\", line 81, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\MADHAVI\\anaconda3\\lib\\asyncio\\selector_events.py\", line 120, in _read_from_self\n",
      "    data = self._ssock.recv(4096)\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "Exception in callback BaseSelectorEventLoop._read_from_self()\n",
      "handle: <Handle BaseSelectorEventLoop._read_from_self()>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\MADHAVI\\anaconda3\\lib\\asyncio\\events.py\", line 81, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\MADHAVI\\anaconda3\\lib\\asyncio\\selector_events.py\", line 120, in _read_from_self\n",
      "    data = self._ssock.recv(4096)\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Model3 is the best amongst all as it has high accuracy and low cost.High accuracy which is the proportion of accurately predicted observations compared to the total number of observations leads to high performance measure.At the same time for Model3 the cost is also low which is comparing the models predicted and actual outputs to determine how far off the model was in its predictions.Non-coding Rna is true positive in model3.With regards to precision, correctly predicted positive observations of non coding Rna to the the total predicted observations that are positive leads to positive predictive value which is high in Model3 so its good.Furthermore,Recall which is a true positive rate resulting into a true positive samples and true negative samples that are predicted.In Task P and most of the tasks,recall value is low and as the precision is high,so most of its predicted labels are correct when compared to the labels that are trained.F1 score is also higher for Model3 which is again good.Matthews correlation coefficient is also close to +1 which indicates that model3 is a perfect model and the false discovery rate is below or closely to 0.05 in model 3 overall and hence are considered real or trusted model'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in callback BaseSelectorEventLoop._read_from_self()\n",
      "handle: <Handle BaseSelectorEventLoop._read_from_self()>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\MADHAVI\\anaconda3\\lib\\asyncio\\events.py\", line 81, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\MADHAVI\\anaconda3\\lib\\asyncio\\selector_events.py\", line 120, in _read_from_self\n",
      "    data = self._ssock.recv(4096)\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "Exception in callback BaseSelectorEventLoop._read_from_self()\n",
      "handle: <Handle BaseSelectorEventLoop._read_from_self()>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\MADHAVI\\anaconda3\\lib\\asyncio\\events.py\", line 81, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\MADHAVI\\anaconda3\\lib\\asyncio\\selector_events.py\", line 120, in _read_from_self\n",
      "    data = self._ssock.recv(4096)\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "Exception in callback BaseSelectorEventLoop._read_from_self()\n",
      "handle: <Handle BaseSelectorEventLoop._read_from_self()>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\MADHAVI\\anaconda3\\lib\\asyncio\\events.py\", line 81, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\MADHAVI\\anaconda3\\lib\\asyncio\\selector_events.py\", line 120, in _read_from_self\n",
      "    data = self._ssock.recv(4096)\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "Exception in callback BaseSelectorEventLoop._read_from_self()\n",
      "handle: <Handle BaseSelectorEventLoop._read_from_self()>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\MADHAVI\\anaconda3\\lib\\asyncio\\events.py\", line 81, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\MADHAVI\\anaconda3\\lib\\asyncio\\selector_events.py\", line 120, in _read_from_self\n",
      "    data = self._ssock.recv(4096)\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "Exception in callback BaseSelectorEventLoop._read_from_self()\n",
      "handle: <Handle BaseSelectorEventLoop._read_from_self()>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\MADHAVI\\anaconda3\\lib\\asyncio\\events.py\", line 81, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\MADHAVI\\anaconda3\\lib\\asyncio\\selector_events.py\", line 120, in _read_from_self\n",
      "    data = self._ssock.recv(4096)\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "Exception in callback BaseSelectorEventLoop._read_from_self()\n",
      "handle: <Handle BaseSelectorEventLoop._read_from_self()>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\MADHAVI\\anaconda3\\lib\\asyncio\\events.py\", line 81, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\MADHAVI\\anaconda3\\lib\\asyncio\\selector_events.py\", line 120, in _read_from_self\n",
      "    data = self._ssock.recv(4096)\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n"
     ]
    }
   ],
   "source": [
    "\"Model3 is the best amongst all as it has high accuracy and low cost.High accuracy which is the proportion of accurately predicted observations compared to the total number of observations leads to high performance measure.At the same time for Model3 the cost is also low which is comparing the models predicted and actual outputs to determine how far off the model was in its predictions.Non-coding Rna is true positive in model3.With regards to precision, correctly predicted positive observations of non coding Rna to the the total predicted observations that are positive leads to positive predictive value which is high in Model3 so its good.Furthermore,Recall which is a true positive rate resulting into a true positive samples and true negative samples that are predicted.In Task P and most of the tasks,recall value is low and as the precision is high,so most of its predicted labels are correct when compared to the labels that are trained.F1 score is also higher for Model3 which is again good.Matthews correlation coefficient is also close to +1 which indicates that model3 is a perfect model and the false discovery rate is below or closely to 0.05 in model 3 overall and hence are considered real or trusted model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821e9cea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be2434a5",
   "metadata": {},
   "source": [
    "## Task: X\n",
    "Again a followup of Tasks O and P: Please scale the given validation dataset with an alternate scaling technique you can think of and repeat Task P with the modified scaled validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d0ff9a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[0.83137045, 0.12121212, 0.26729745, ..., 0.11082144, 0.55121274,\n",
      "        0.56313463],\n",
      "       [0.86991435, 0.12121212, 0.28925885, ..., 0.78888948, 0.46590509,\n",
      "        0.37143046],\n",
      "       [0.84528908, 0.15151515, 0.23298359, ..., 0.30918873, 0.36176495,\n",
      "        0.68077103],\n",
      "       ...,\n",
      "       [0.54657388, 0.8030303 , 0.34279061, ..., 0.34279061, 0.32195024,\n",
      "        0.62903215],\n",
      "       [0.89239829, 0.12121212, 0.25357191, ..., 0.27442788, 0.23712884,\n",
      "        0.77413394],\n",
      "       [0.58779443, 0.8030303 , 0.35449265, ..., 0.27587591, 0.34861068,\n",
      "        0.65898851]]), array([0, 0, 0, ..., 1, 0, 1], dtype=int64))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MADHAVI\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.24.2 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      " 17%|██████████████                                                                      | 1/6 [00:00<00:04,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           model_name  Accuracy Precision  Recall   F1 MCC FDR\n",
      "0  models/Model_1.pkl  0.667667  0         0.0     0.0  -1  -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MADHAVI\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator KNeighborsClassifier from version 0.24.2 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      " 33%|████████████████████████████                                                        | 2/6 [00:29<01:08, 17.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           model_name  Accuracy Precision  Recall   F1 MCC FDR\n",
      "0  models/Model_1.pkl  0.667667  0         0.0     0.0  -1  -1\n",
      "1  models/Model_2.pkl  0.667667  0         0.0     0.0  -1  -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MADHAVI\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator SVC from version 0.24.2 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      " 50%|██████████████████████████████████████████                                          | 3/6 [02:11<02:47, 55.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           model_name  Accuracy Precision  Recall   F1 MCC FDR\n",
      "0  models/Model_1.pkl  0.667667  0         0.0     0.0  -1  -1\n",
      "1  models/Model_2.pkl  0.667667  0         0.0     0.0  -1  -1\n",
      "2  models/Model_3.pkl  0.667667  0         0.0     0.0  -1  -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MADHAVI\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.24.2 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "C:\\Users\\MADHAVI\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator MLPClassifier from version 0.24.2 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      " 67%|████████████████████████████████████████████████████████                            | 4/6 [02:12<01:08, 34.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           model_name  Accuracy Precision   Recall        F1       MCC  FDR\n",
      "0  models/Model_1.pkl  0.667667  0         0.00000  0.000000  -1        -1 \n",
      "1  models/Model_2.pkl  0.667667  0         0.00000  0.000000  -1        -1 \n",
      "2  models/Model_3.pkl  0.667667  0         0.00000  0.000000  -1        -1 \n",
      "3  models/Model_4.pkl  0.667717  1.0       0.00015  0.000301  0.010023  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MADHAVI\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.24.2 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      " 83%|██████████████████████████████████████████████████████████████████████              | 5/6 [02:13<00:22, 22.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           model_name  Accuracy Precision   Recall        F1       MCC  FDR\n",
      "0  models/Model_1.pkl  0.667667  0         0.00000  0.000000  -1        -1 \n",
      "1  models/Model_2.pkl  0.667667  0         0.00000  0.000000  -1        -1 \n",
      "2  models/Model_3.pkl  0.667667  0         0.00000  0.000000  -1        -1 \n",
      "3  models/Model_4.pkl  0.667717  1.0       0.00015  0.000301  0.010023  0.0\n",
      "4  models/Model_5.pkl  0.667667  0         0.00000  0.000000  -1        -1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MADHAVI\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator SVC from version 0.24.2 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [02:47<00:00, 27.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           model_name  Accuracy Precision   Recall        F1       MCC  FDR\n",
      "0  models/Model_1.pkl  0.667667  0         0.00000  0.000000  -1        -1 \n",
      "1  models/Model_2.pkl  0.667667  0         0.00000  0.000000  -1        -1 \n",
      "2  models/Model_3.pkl  0.667667  0         0.00000  0.000000  -1        -1 \n",
      "3  models/Model_4.pkl  0.667717  1.0       0.00015  0.000301  0.010023  0.0\n",
      "4  models/Model_5.pkl  0.667667  0         0.00000  0.000000  -1        -1 \n",
      "5  models/Model_6.pkl  0.667667  0         0.00000  0.000000  -1        -1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Print as a dataframe containing:\n",
    "# {model_name,acc,prec,rec,f1,mcc,FDR} for each of the N models (listed in model_files) predicting the target variables\n",
    "#  of the validation data.\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "val2=validation.iloc[:,:-1]\n",
    "for i in val2.axes[1]:\n",
    "    m=np.max(training.iloc[:,i])\n",
    "    s=np.min(training.iloc[:,i])\n",
    "    val2.iloc[:,i]=(validation.iloc[:,i]-s)/(m-s)\n",
    "X_validation_scaled_1=(np.array(val2),np.array(validation.iloc[:,8]))\n",
    "print(X_validation_scaled_1)\n",
    "result7 = pd.DataFrame(columns=['model_name','Accuracy','Precision','Recall','F1','MCC','FDR'])\n",
    "\n",
    "model_files=[\"models/Model_1.pkl\",\"models/Model_2.pkl\",\"models/Model_3.pkl\",\\\n",
    "                            \"models/Model_4.pkl\",\"models/Model_5.pkl\",\"models/Model_6.pkl\"]\n",
    "\n",
    "\n",
    "for file_name in tqdm(model_files):\n",
    "    in_file = open(file_name,'rb')\n",
    "    model = pickle.load(in_file)\n",
    "    in_file.close()\n",
    "\n",
    "    #Do the prediction by calling the \"predict\" member function of the model object on the\n",
    "    # validation data with the 8 features\n",
    "    X_test = val2.iloc[:,:8]\n",
    "    y_test = validation.iloc[:,-1]\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    \n",
    "    #@TODO: Complete and revise the following...\n",
    "    conf_mat = []\n",
    "    acc = 0\n",
    "    prec = 0\n",
    "    rec = 0\n",
    "    f1 = 0\n",
    "    mcc = 0\n",
    "    fdr = 0\n",
    "    \n",
    "    conf_mat = confusion_matrix(y_test,y_pred)\n",
    "    acc = accuracy(conf_mat)\n",
    "    prec = precision(conf_mat)\n",
    "    rec = recall(conf_mat)\n",
    "    f1 = F1(conf_mat)\n",
    "    mcc = MCC(conf_mat)\n",
    "    fdr = FDR(conf_mat)\n",
    "    \n",
    "    result7= result7.append(pd.Series([file_name,acc,prec,rec,f1,mcc,fdr],index=result7.columns),ignore_index=True)\n",
    "    print(result7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3adf9c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bdf41c13",
   "metadata": {},
   "source": [
    "## Task: Y\n",
    "Print the model name with path which is performing superior in terms of accuracy, given the performance result dataframe from “X”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b30e3428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           model_name  Accuracy Precision   Recall        F1       MCC  FDR\n",
      "3  models/Model_4.pkl  0.667717  1.0       0.00015  0.000301  0.010023  0.0\n"
     ]
    }
   ],
   "source": [
    "maxvalue=result7['Accuracy'].max()\n",
    "print(result7[result7.Accuracy==maxvalue])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f35599",
   "metadata": {},
   "source": [
    "## Task: Z\n",
    "Print the model name with path which is performing the worst in terms of recall, given the performance result dataframe from “X”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ea65917d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           model_name  Accuracy Precision  Recall   F1 MCC FDR\n",
      "0  models/Model_1.pkl  0.667667  0         0.0     0.0  -1  -1\n",
      "1  models/Model_2.pkl  0.667667  0         0.0     0.0  -1  -1\n",
      "2  models/Model_3.pkl  0.667667  0         0.0     0.0  -1  -1\n",
      "4  models/Model_5.pkl  0.667667  0         0.0     0.0  -1  -1\n",
      "5  models/Model_6.pkl  0.667667  0         0.0     0.0  -1  -1\n"
     ]
    }
   ],
   "source": [
    "minvalue=result7['Recall'].min()\n",
    "print(result7[result7.Recall==minvalue])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b084cd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3df2fd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
